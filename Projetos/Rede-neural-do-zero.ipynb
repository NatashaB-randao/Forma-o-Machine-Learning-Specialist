{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O banco de dados MNIST é um grande banco de dados de dígitos manuscritos, comumente usado para treinar vários sistemas de processamento de imagens. O banco de dados também é amplamente utilizado para treinamento e teste no campo do aprendizado de máquina.\n",
    "\n",
    "A base de dados do MNIST contém 60.000 imagens de preparação e 10.000 imagens de teste. \n",
    "\n",
    "É um tipo de Rede Neural usada para resolver problemas numéricos - números escritos à mão. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() #definindo a conversão de imagem para tensor\n",
    "\n",
    "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # Carrega a parte de treino do dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # Carrega um buffer para pegar os dados por partes\n",
    "\n",
    "valset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform)  # Carrega a parte de validação\n",
    "valloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)   # Cria um buffer para pegar os dados por partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZ8UlEQVR4nO3df2hV9/3H8df1R261Ta6LMbnJjC7aVreqGXOaBVuNGIwZiL8G2nagRRRdLNOsa3G0mmyDbBb8lhanf01XqNoJVakwwcbkSrfo0CoiW4MJ2VRMYivk3hhrFPP5/iHeeTWp3uu9ed8bnw84YO49J/ft6eE+e3Ovn3icc04AAPSzQdYDAACeTAQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGI9wP16enp0+fJlpaeny+PxWI8DAIiSc06dnZ3Ky8vToEF9v85JugBdvnxZ+fn51mMAAB7TxYsXNXr06D7vT7oApaenS7ozeEZGhvE0AIBohUIh5efnh5/P+5KwAG3btk3vvvuu2traVFhYqA8++EDTp09/6HF3f+yWkZFBgAAghT3sbZSEfAjh448/VmVlpTZv3qwvvvhChYWFKisr05UrVxLxcACAFJSQAG3dulWrVq3Sa6+9ph/84AfasWOHhg8frj//+c+JeDgAQAqKe4Bu3rypU6dOqbS09H8PMmiQSktL1dDQ8MD+3d3dCoVCERsAYOCLe4C+/vpr3b59Wzk5ORG35+TkqK2t7YH9a2pq5PP5whufgAOAJ4P5P0TduHGjgsFgeLt48aL1SACAfhD3T8FlZWVp8ODBam9vj7i9vb1dfr//gf29Xq+8Xm+8xwAAJLm4vwJKS0vT1KlTVVtbG76tp6dHtbW1Ki4ujvfDAQBSVEL+HVBlZaWWL1+uH//4x5o+fbree+89dXV16bXXXkvEwwEAUlBCArR06VJ99dVX2rRpk9ra2vTDH/5Qhw8ffuCDCQCAJ5fHOeesh7hXKBSSz+dTMBhkJQQASEGP+jxu/ik4AMCTiQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmIh7gKqqquTxeCK2iRMnxvthAAApbkgivukLL7ygzz777H8PMiQhDwMASGEJKcOQIUPk9/sT8a0BAANEQt4DOn/+vPLy8jRu3Di9+uqrunDhQp/7dnd3KxQKRWwAgIEv7gEqKirSrl27dPjwYW3fvl0tLS166aWX1NnZ2ev+NTU18vl84S0/Pz/eIwEAkpDHOecS+QAdHR0aO3astm7dqpUrVz5wf3d3t7q7u8Nfh0Ih5efnKxgMKiMjI5GjAQASIBQKyefzPfR5POGfDhgxYoSef/55NTU19Xq/1+uV1+tN9BgAgCST8H8HdO3aNTU3Nys3NzfRDwUASCFxD9Abb7yhQCCg//znP/rHP/6hRYsWafDgwXr55Zfj/VAAgBQW9x/BXbp0SS+//LKuXr2qUaNG6cUXX9Tx48c1atSoeD8UACCFxT1Ae/fujfe3BAAT9fX1/XJMLKqqqvrlcRKJteAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMJ/42o0XrU36QHpLL+WuSypKQk6mNiPS6WxTEDgUDUx/TXYp8DVX885T/q8zivgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCC1bCBe8Sy0nJ1dXW/PA5wryR76o7AatgAgKRGgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJgYYj0A8DCxLNwZ62KfsSwsitiVlJT0y+PMmjUrpuOqqqriOwgi8AoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBYqToV7Es7jgQFwiNZRHOWBbUDAQCUR8T62PF8nfqr8VIkZx4BQQAMEGAAAAmog7QsWPHNH/+fOXl5cnj8ejAgQMR9zvntGnTJuXm5mrYsGEqLS3V+fPn4zUvAGCAiDpAXV1dKiws1LZt23q9f8uWLXr//fe1Y8cOnThxQk8//bTKysp048aNxx4WADBwRP0hhPLycpWXl/d6n3NO7733nt5++20tWLBAkvThhx8qJydHBw4c0LJlyx5vWgDAgBHX94BaWlrU1tam0tLS8G0+n09FRUVqaGjo9Zju7m6FQqGIDQAw8MU1QG1tbZKknJyciNtzcnLC992vpqZGPp8vvOXn58dzJABAkjL/FNzGjRsVDAbD28WLF61HAgD0g7gGyO/3S5La29sjbm9vbw/fdz+v16uMjIyIDQAw8MU1QAUFBfL7/aqtrQ3fFgqFdOLECRUXF8fzoQAAKS7qT8Fdu3ZNTU1N4a9bWlp05swZZWZmasyYMVq/fr1+//vf67nnnlNBQYHeeecd5eXlaeHChfGcGwCQ4qIO0MmTJzV79uzw15WVlZKk5cuXa9euXXrzzTfV1dWl1atXq6OjQy+++KIOHz6sp556Kn5TAwBSnsc556yHuFcoFJLP51MwGOT9oCRXX18f9TH3/s9LMoplcczNmzf3y+MAqeJRn8fNPwUHAHgyESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwETUv44BuCuW1bCTXSx/p1iOiWUF7aqqqqiPAZIZr4AAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMe55yzHuJeoVBIPp9PwWBQGRkZ1uMgzjwej/UIKaukpCTqY+rq6uI/CPAQj/o8zisgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDEEOsB8GSJZXHM+vr6+A/Sh+rq6n57rGjFch5iXfw1lv9OsSyWiicbr4AAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMe55yzHuJeoVBIPp9PwWBQGRkZ1uMADxXLIqGxLHran4uyxrKwaCwLmGJgetTncV4BAQBMECAAgImoA3Ts2DHNnz9feXl58ng8OnDgQMT9K1askMfjidjmzZsXr3kBAANE1AHq6upSYWGhtm3b1uc+8+bNU2tra3jbs2fPYw0JABh4ov6NqOXl5SovL//Wfbxer/x+f8xDAQAGvoS8B1RfX6/s7GxNmDBBa9eu1dWrV/vct7u7W6FQKGIDAAx8cQ/QvHnz9OGHH6q2tlZ//OMfFQgEVF5ertu3b/e6f01NjXw+X3jLz8+P90gAgCQU9Y/gHmbZsmXhP0+ePFlTpkzR+PHjVV9frzlz5jyw/8aNG1VZWRn+OhQKESEAeAIk/GPY48aNU1ZWlpqamnq93+v1KiMjI2IDAAx8CQ/QpUuXdPXqVeXm5ib6oQAAKSTqH8Fdu3Yt4tVMS0uLzpw5o8zMTGVmZqq6ulpLliyR3+9Xc3Oz3nzzTT377LMqKyuL6+AAgNQWdYBOnjyp2bNnh7+++/7N8uXLtX37dp09e1Z/+ctf1NHRoby8PM2dO1e/+93v5PV64zc1ACDlsRjpAFNVVRX1MbEsPPk4xyE2Ho/HeoRvtXnz5qiPieV6RfJjMVIAQFIjQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACVbDHmD6c8VkVj/uX7Gcu+rq6vgP0odYVkevq6uL/yAwx2rYAICkRoAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYGGI9AOIrlgUh6+vrY3qsWBa6jOUYFj0FBiZeAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJjzOOWc9xL1CoZB8Pp+CwaAyMjKsx3kixLpwZywLiya7WBZznTVrVvwH6UWyn++6urqoj4nlfCP5PerzOK+AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATLEaKmM2ePTvqY+rr6+M/CJJCkj2VwBCLkQIAkhoBAgCYiCpANTU1mjZtmtLT05Wdna2FCxeqsbExYp8bN26ooqJCI0eO1DPPPKMlS5aovb09rkMDAFJfVAEKBAKqqKjQ8ePHdeTIEd26dUtz585VV1dXeJ8NGzbo008/1b59+xQIBHT58mUtXrw47oMDAFLbY30I4auvvlJ2drYCgYBmzpypYDCoUaNGaffu3frZz34mSfryyy/1/e9/Xw0NDfrJT37y0O/JhxBSBx9CwL34EALu6pcPIQSDQUlSZmamJOnUqVO6deuWSktLw/tMnDhRY8aMUUNDQ6/fo7u7W6FQKGIDAAx8MQeop6dH69ev14wZMzRp0iRJUltbm9LS0jRixIiIfXNyctTW1tbr96mpqZHP5wtv+fn5sY4EAEghMQeooqJC586d0969ex9rgI0bNyoYDIa3ixcvPtb3AwCkhiGxHLRu3TodOnRIx44d0+jRo8O3+/1+3bx5Ux0dHRGvgtrb2+X3+3v9Xl6vV16vN5YxAAApLKpXQM45rVu3Tvv379fRo0dVUFAQcf/UqVM1dOhQ1dbWhm9rbGzUhQsXVFxcHJ+JAQADQlSvgCoqKrR7924dPHhQ6enp4fd1fD6fhg0bJp/Pp5UrV6qyslKZmZnKyMjQ66+/ruLi4kf6BBwA4MkRVYC2b98uSSopKYm4fefOnVqxYoUk6f/+7/80aNAgLVmyRN3d3SorK9Of/vSnuAwLABg4WIwU/aqqqirqYwKBQNTH8O+NHk9dXV3Ux9z/P6Z4crEYKQAgqREgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEq2FjQIp1Nezq6up+e6z+EMuq1hIrW+PxsBo2ACCpESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmWIwUABBXLEYKAEhqBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImoAlRTU6Np06YpPT1d2dnZWrhwoRobGyP2KSkpkcfjidjWrFkT16EBAKkvqgAFAgFVVFTo+PHjOnLkiG7duqW5c+eqq6srYr9Vq1aptbU1vG3ZsiWuQwMAUt+QaHY+fPhwxNe7du1Sdna2Tp06pZkzZ4ZvHz58uPx+f3wmBAAMSI/1HlAwGJQkZWZmRtz+0UcfKSsrS5MmTdLGjRt1/fr1Pr9Hd3e3QqFQxAYAGPiiegV0r56eHq1fv14zZszQpEmTwre/8sorGjt2rPLy8nT27Fm99dZbamxs1CeffNLr96mpqVF1dXWsYwAAUpTHOediOXDt2rX629/+ps8//1yjR4/uc7+jR49qzpw5ampq0vjx4x+4v7u7W93d3eGvQ6GQ8vPzFQwGlZGREctoAABDoVBIPp/voc/jMb0CWrdunQ4dOqRjx459a3wkqaioSJL6DJDX65XX641lDABACosqQM45vf7669q/f7/q6+tVUFDw0GPOnDkjScrNzY1pQADAwBRVgCoqKrR7924dPHhQ6enpamtrkyT5fD4NGzZMzc3N2r17t376059q5MiROnv2rDZs2KCZM2dqypQpCfkLAABSU1TvAXk8nl5v37lzp1asWKGLFy/q5z//uc6dO6euri7l5+dr0aJFevvttx/5/ZxH/dkhACA5JeQ9oIe1Kj8/X4FAIJpvCQB4QrEWHADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAxBDrAe7nnJMkhUIh40kAALG4+/x99/m8L0kXoM7OTklSfn6+8SQAgMfR2dkpn8/X5/0e97BE9bOenh5dvnxZ6enp8ng8EfeFQiHl5+fr4sWLysjIMJrQHufhDs7DHZyHOzgPdyTDeXDOqbOzU3l5eRo0qO93epLuFdCgQYM0evTob90nIyPjib7A7uI83MF5uIPzcAfn4Q7r8/Btr3zu4kMIAAATBAgAYCKlAuT1erV582Z5vV7rUUxxHu7gPNzBebiD83BHKp2HpPsQAgDgyZBSr4AAAAMHAQIAmCBAAAATBAgAYCJlArRt2zZ973vf01NPPaWioiL985//tB6p31VVVcnj8URsEydOtB4r4Y4dO6b58+crLy9PHo9HBw4ciLjfOadNmzYpNzdXw4YNU2lpqc6fP28zbAI97DysWLHigetj3rx5NsMmSE1NjaZNm6b09HRlZ2dr4cKFamxsjNjnxo0bqqio0MiRI/XMM89oyZIlam9vN5o4MR7lPJSUlDxwPaxZs8Zo4t6lRIA+/vhjVVZWavPmzfriiy9UWFiosrIyXblyxXq0fvfCCy+otbU1vH3++efWIyVcV1eXCgsLtW3btl7v37Jli95//33t2LFDJ06c0NNPP62ysjLduHGjnydNrIedB0maN29exPWxZ8+efpww8QKBgCoqKnT8+HEdOXJEt27d0ty5c9XV1RXeZ8OGDfr000+1b98+BQIBXb58WYsXLzacOv4e5TxI0qpVqyKuhy1bthhN3AeXAqZPn+4qKirCX9++fdvl5eW5mpoaw6n63+bNm11hYaH1GKYkuf3794e/7unpcX6/37377rvh2zo6OpzX63V79uwxmLB/3H8enHNu+fLlbsGCBSbzWLly5YqT5AKBgHPuzn/7oUOHun379oX3+fe//+0kuYaGBqsxE+7+8+Ccc7NmzXK//OUv7YZ6BEn/CujmzZs6deqUSktLw7cNGjRIpaWlamhoMJzMxvnz55WXl6dx48bp1Vdf1YULF6xHMtXS0qK2traI68Pn86moqOiJvD7q6+uVnZ2tCRMmaO3atbp69ar1SAkVDAYlSZmZmZKkU6dO6datWxHXw8SJEzVmzJgBfT3cfx7u+uijj5SVlaVJkyZp48aNun79usV4fUq6xUjv9/XXX+v27dvKycmJuD0nJ0dffvml0VQ2ioqKtGvXLk2YMEGtra2qrq7WSy+9pHPnzik9Pd16PBNtbW2S1Ov1cfe+J8W8efO0ePFiFRQUqLm5Wb/5zW9UXl6uhoYGDR482Hq8uOvp6dH69es1Y8YMTZo0SdKd6yEtLU0jRoyI2HcgXw+9nQdJeuWVVzR27Fjl5eXp7Nmzeuutt9TY2KhPPvnEcNpISR8g/E95eXn4z1OmTFFRUZHGjh2rv/71r1q5cqXhZEgGy5YtC/958uTJmjJlisaPH6/6+nrNmTPHcLLEqKio0Llz556I90G/TV/nYfXq1eE/T548Wbm5uZozZ46am5s1fvz4/h6zV0n/I7isrCwNHjz4gU+xtLe3y+/3G02VHEaMGKHnn39eTU1N1qOYuXsNcH08aNy4ccrKyhqQ18e6det06NAh1dXVRfz6Fr/fr5s3b6qjoyNi/4F6PfR1HnpTVFQkSUl1PSR9gNLS0jR16lTV1taGb+vp6VFtba2Ki4sNJ7N37do1NTc3Kzc313oUMwUFBfL7/RHXRygU0okTJ5746+PSpUu6evXqgLo+nHNat26d9u/fr6NHj6qgoCDi/qlTp2ro0KER10NjY6MuXLgwoK6Hh52H3pw5c0aSkut6sP4UxKPYu3ev83q9bteuXe5f//qXW716tRsxYoRra2uzHq1f/epXv3L19fWupaXF/f3vf3elpaUuKyvLXblyxXq0hOrs7HSnT592p0+fdpLc1q1b3enTp91///tf55xzf/jDH9yIESPcwYMH3dmzZ92CBQtcQUGB++abb4wnj69vOw+dnZ3ujTfecA0NDa6lpcV99tln7kc/+pF77rnn3I0bN6xHj5u1a9c6n8/n6uvrXWtra3i7fv16eJ81a9a4MWPGuKNHj7qTJ0+64uJiV1xcbDh1/D3sPDQ1Nbnf/va37uTJk66lpcUdPHjQjRs3zs2cOdN48kgpESDnnPvggw/cmDFjXFpamps+fbo7fvy49Uj9bunSpS43N9elpaW57373u27p0qWuqanJeqyEq6urc5Ie2JYvX+6cu/NR7Hfeecfl5OQ4r9fr5syZ4xobG22HToBvOw/Xr193c+fOdaNGjXJDhw51Y8eOdatWrRpw/5PW299fktu5c2d4n2+++cb94he/cN/5znfc8OHD3aJFi1xra6vd0AnwsPNw4cIFN3PmTJeZmem8Xq979tln3a9//WsXDAZtB78Pv44BAGAi6d8DAgAMTAQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACAif8H++QstIo4SA8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "imagens, etiquetas = next(dataiter)\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');  # Exibe a primeira imagem do lote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape)     #para verificar as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape)   #para verificar as dimensões do tensor de cada etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128)    # Camada de entrada, 784 neurônios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(128, 64)       # Camada interna 1, 128 neurônios que se ligam a 64\n",
    "        self.linear3 = nn.Linear(64, 10)        # Camada interna 2, 64 neurônios que se ligam a 10\n",
    "        # Para a Camada de saída não é necessário definir nada, pois só precisamos pegar o output da camada interna 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X))     # Função de Ativação da Camada de Entrada para a Camada Interna 1 \n",
    "        X = F.relu(self.linear2(X))     # Função de Ativação da Camada Interna 1 para a Camada Interna 2\n",
    "        X = F.relu(self.linear3(X))     # Função de Ativação da Camada Interna 2 para a Camada de Saída, nesse caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1)  # Dados utilizados para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)      # Define a Política de Atualização dos Pesos e da Bias\n",
    "    inicio = time()     # Timer para sabermos quanto tempo levou o treino\n",
    "\n",
    "    criterio = nn.NLLLoss()     # Definindo o Critério para Calcular a Perda\n",
    "    EPOCHS = 10                 # Número de epochs que o algoritmo rodará\n",
    "    modelo.train()              # Ativando o Modo de Treinamento do Modelo\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0     # Inicialização da Perda Acumulada da epoch em questão\n",
    "\n",
    "        for imagens, etiquetas in trainloader:\n",
    "\n",
    "            imagens = imagens.view(imagens.shape[0], -1)    # Convertendo as imagens para \"vetores\" de 28*28 casas para ficarem compatíveis com a  \n",
    "            otimizador.zero_grad()                          # Zerando os gradientes por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device))             # Colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device))      # Calculando a perda da epoch em questão\n",
    "\n",
    "            perda_instantanea.backward()                    # Back Propagation a partir da perda\n",
    "\n",
    "            otimizador.step()                               # Atualizando os pesos e a bias\n",
    "\n",
    "            perda_acumulada += perda_instantanea.item()     # Atualização da Perda Acumulada\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
    "    print(\"\\nTempo de treino (em minutos) =\", (time()-inicio/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, valloader, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    for imagens, etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            # Desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device))          # Converte output para escala normal(lembrando que é um tensor)\n",
    "                probab = list(logps.cpu().numpy()[0])\n",
    "                etiqueta_pred = probab.index(max(probab))   # Converte o tensor em um número, no caso, o número que o modelo previu como correto\n",
    "                etiqueta_certa = etiquetas.numpy()[i]\n",
    "                if etiqueta_certa == etiqueta_pred:        # Compara a previsão com o valor correto\n",
    "                    conta_corretas += 1\n",
    "                conta_todas += 1\n",
    "\n",
    "        print(\"Total de imagens testada =\", conta_todas)\n",
    "        print(\"Precisão do modelo = {}%\".format(conta_corretas*100/conta_todas))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
