{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "**Transfer Learning (ou Aprendizagem por Transferência)** é uma técnica em Machine Learning e Deep Learning onde um modelo treinado em uma tarefa é reutilizado como o ponto de partida para um modelo em uma segunda tarefa relacionada. Em vez de treinar um modelo do zero, o que pode ser muito demorado e requerer grandes quantidades de dados, Transfer Learning aproveita o conhecimento já adquirido em um modelo pré-treinado para acelerar e melhorar o desempenho em uma nova tarefa.\n",
    "\n",
    "### Funcionamento do Transfer Learning\n",
    "\n",
    "1. **Modelo Pré-treinado**: Um modelo é treinado em um grande conjunto de dados e em uma tarefa específica (por exemplo, a classificação de imagens no ImageNet).\n",
    "2. **Transferência do Conhecimento**: As camadas iniciais desse modelo capturam características genéricas das imagens (como bordas, texturas, formas), enquanto as camadas finais são mais específicas para a tarefa original. No Transfer Learning, essas camadas iniciais são reutilizadas.\n",
    "3. **Adaptação**: O modelo é então ajustado para a nova tarefa, que pode envolver:\n",
    "   - **Congelar** algumas das camadas iniciais e treinar apenas as últimas camadas com o novo conjunto de dados.\n",
    "   - **Treinamento Fino (Fine-tuning)**, onde todo o modelo é treinado novamente com uma taxa de aprendizado mais baixa.\n",
    "\n",
    "### Aplicação Prática\n",
    "\n",
    "Neste projeto, estamos utilizando um modelo pré-treinado em um dataset bem conhecido (como o ImageNet) e adaptando esse modelo para classificar imagens de gatos e cachorros. A abordagem geral inclui os seguintes passos:\n",
    "\n",
    "1. **Carregar o modelo pré-treinado**: Utilizando bibliotecas como Keras, TensorFlow ou PyTorch para carregar um modelo que já foi treinado em um grande conjunto de dados.\n",
    "2. **Modificar a arquitetura**: Adaptar a última camada do modelo para ter o mesmo número de classes que o nosso problema (neste caso, duas classes: gatos e cachorros).\n",
    "3. **Congelar camadas**: Congelar algumas das primeiras camadas do modelo para preservar as características genéricas aprendidas.\n",
    "4. **Treinar o modelo**: Usar nosso conjunto de dados específico (gatos e cachorros) para ajustar as camadas finais do modelo e refinar o desempenho.\n",
    "\n",
    "### Exemplo no COLAB\n",
    "\n",
    "O exemplo no link [Transfer Learning com o Dataset MNIST](https://colab.research.google.com/github/kylemath/ml4a-guides/blob/master/notebooks/transfer-learning.ipynb) demonstra como aplicar Transfer Learning usando o dataset MNIST. Para este projeto, seguimos uma abordagem similar, mas adaptando para o dataset de gatos e cachorros, conforme descrito no link [Cats vs Dogs Dataset](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs).\n",
    "\n",
    "### Benefícios do Transfer Learning\n",
    "\n",
    "- **Redução do Tempo de Treinamento**: O modelo já tem um bom entendimento das características básicas das imagens, então o tempo necessário para treinar é reduzido.\n",
    "- **Menos Dados Necessários**: Como o modelo já foi treinado em uma grande quantidade de dados, a quantidade de dados necessária para a nova tarefa é menor.\n",
    "- **Melhor Desempenho**: Utilizando um modelo pré-treinado que já foi ajustado para capturar características relevantes, o desempenho na nova tarefa pode ser melhor do que treinar um modelo do zero.\n",
    "\n",
    "### Exemplos Comuns\n",
    "\n",
    "Transfer Learning é amplamente utilizado em várias áreas, como:\n",
    "- **Visão Computacional**: Classificação de imagens, detecção de objetos, segmentação de imagens.\n",
    "- **Processamento de Linguagem Natural (NLP)**: Tradução de texto, classificação de texto, resposta a perguntas.\n",
    "- **Reconhecimento de Voz**: Identificação de locutores, transcrição de fala.\n",
    "\n",
    "### Conclusão\n",
    "\n",
    "Transfer Learning é uma poderosa técnica em Deep Learning que permite reutilizar e adaptar modelos pré-treinados para novas tarefas, economizando tempo e recursos e melhorando o desempenho em tarefas relacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Importa o módulo os para interagir com o sistema operacional, como manipulação de diretórios e variáveis de ambiente\n",
    "\n",
    "# if using Theano with GPU\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # Define o backend do Keras para TensorFlow caso esteja usando Theano com GPU (comentado, pois estamos usando TensorFlow por padrão)\n",
    "\n",
    "import random  # Importa o módulo random para gerar números aleatórios\n",
    "import numpy as np  # Importa o numpy com o alias np, uma biblioteca fundamental para computação numérica em Python\n",
    "import keras  # Importa o Keras, uma biblioteca popular de deep learning que fornece uma API simples para construção e treinamento de modelos de redes neurais\n",
    "\n",
    "import matplotlib.pyplot as plt  # Importa matplotlib.pyplot com o alias plt, uma biblioteca para plotagem de gráficos em Python\n",
    "from matplotlib.pyplot import imshow  # Importa a função imshow do matplotlib.pyplot para exibir imagens\n",
    "\n",
    "from keras.preprocessing import image  # Importa submódulos de pré-processamento de imagens do Keras, úteis para carregar e pré-processar imagens\n",
    "from keras.applications.imagenet_utils import preprocess_input  # Importa preprocess_input de keras.applications.imagenet_utils, uma função para pré-processar imagens de acordo com o padrão do ImageNet\n",
    "from keras.models import Sequential  # Importa a classe Sequential do Keras para criar modelos sequenciais de redes neurais\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation  # Importa camadas específicas do Keras usadas na construção de redes neurais\n",
    "from keras.layers import Conv2D, MaxPooling2D  # Importa camadas convolucionais (Conv2D) e de max pooling (MaxPooling2D), fundamentais para processar dados de imagem em redes convolucionais\n",
    "from keras.models import Model  # Importa a classe Model do Keras para criar modelos mais complexos e customizados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo um Dataset\n",
    "\n",
    "O primeiro passo é carregar nossos dados. Para este exemplo, utilizaremos o dataset de Gatos e Cachorros, que contém imagens rotuladas de duas categorias: gatos e cachorros. O dataset já está organizado com imagens divididas em pastas para cada classe.\n",
    "\n",
    "Para obter este dataset, você pode seguir estas etapas:\n",
    "\n",
    "1. **Baixar o dataset**: Utilize o comando `wget` para baixar o dataset, ou você pode usar o link direto para o download. Aqui estão os comandos:\n",
    "\n",
    "    ```bash\n",
    "    wget https://www.microsoft.com/en-us/download/details.aspx?id=54765\n",
    "    ```\n",
    "\n",
    "    Se necessário, descompacte o arquivo:\n",
    "\n",
    "    ```bash\n",
    "    tar -xvzf nome_do_arquivo.tar.gz\n",
    "    ```\n",
    "\n",
    "2. **Organizar o dataset**: Certifique-se de que seu dataset esteja organizado da seguinte forma:\n",
    "    - O diretório principal deve conter subpastas para cada classe (neste caso, uma subpasta para \"gatos\" e outra para \"cachorros\").\n",
    "    - Cada subpasta deve conter as imagens correspondentes à sua classe.\n",
    "\n",
    "3. **Carregar o dataset**: Substitua `root` pelo caminho para o seu diretório de dataset. O código abaixo carrega o dataset personalizado, redimensiona as imagens para 224x224 pixels (necessário para a entrada da VGG16), e prepara as imagens para serem usadas no modelo.\n",
    "\n",
    "    ```python\n",
    "    root = 'caminho/para/seu/dataset'\n",
    "    \n",
    "    # Lista de categorias (pastas) que você deseja incluir no treinamento\n",
    "    categorias = [x[0] for x in os.walk(root) if x[0]][1:]\n",
    "    \n",
    "    # Imprime as categorias disponíveis no dataset\n",
    "    print(categorias)\n",
    "    ```\n",
    "\n",
    "Certifique-se de que a estrutura do diretório esteja correta para que o código funcione corretamente. Se você tiver um estrutura diferente, adapte o código conforme necessário para carregar os dados corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kagglecatsanddogs_5340/PetImages/Cat', 'kagglecatsanddogs_5340/PetImages/Dog']\n"
     ]
    }
   ],
   "source": [
    "root = 'kagglecatsanddogs_5340/PetImages'\n",
    "\n",
    "# Lista de categorias (pastas) que você deseja incluir no treinamento\n",
    "categories = [os.path.join(root, 'Cat'), os.path.join(root, 'Dog')]\n",
    "\n",
    "# Imprime as categorias disponíveis no dataset\n",
    "print(categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Pré-processamento de Imagens\n",
    "\n",
    "Esta função é útil para pré-processar os dados, transformando uma imagem em um vetor de entrada adequado para o modelo.\n",
    "\n",
    "A função get_image carrega uma imagem, redimensiona-a para 224x224 pixels (o tamanho de entrada esperado pela VGG16), e a prepara para ser alimentada na rede neural. A função retorna a imagem original e o vetor de entrada pré-processado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar para carregar a imagem e retornar a imagem e o vetor de entrada\n",
    "def get_image(path):\n",
    "    try:\n",
    "        # Carrega a imagem com o tamanho de entrada esperado (224x224 pixels)\n",
    "        img = image.load_img(path, target_size=(224, 224))\n",
    "        \n",
    "        # Converte a imagem em um array numpy\n",
    "        x = image.img_to_array(img)\n",
    "        \n",
    "        # Adiciona uma dimensão extra ao array para criar um batch do tamanho 1\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        # Pré-processa a imagem para o modelo (no caso da VGG16)\n",
    "        x = preprocess_input(x)\n",
    "        \n",
    "        return img, x\n",
    "    except (IOError, SyntaxError) as e:\n",
    "        print(f\"Erro ao carregar imagem {path}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregar Todas as Imagens da Pasta Raiz\n",
    "\n",
    "Nesta etapa, vamos carregar todas as imagens das pastas de categorias e organizá-las em uma lista. Cada imagem será processada usando a função get_image, e os dados serão armazenados em um formato que inclui a imagem pré-processada e seu rótulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao carregar imagem kagglecatsanddogs_5340/PetImages/Cat/666.jpg: cannot identify image file <_io.BytesIO object at 0x30d6edf30>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao carregar imagem kagglecatsanddogs_5340/PetImages/Dog/11702.jpg: cannot identify image file <_io.BytesIO object at 0x30d602c00>\n",
      "Total de classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Lista para armazenar os dados das imagens\n",
    "data = []\n",
    "\n",
    "# Itera sobre cada categoria\n",
    "for c, category in enumerate(categories):\n",
    "    images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(category) for f in filenames if os.path.splitext(f)[1].lower() in ['.jpg', '.png', '.jpeg']]\n",
    "    \n",
    "    # Processa cada imagem\n",
    "    for img_path in images:\n",
    "        img, x = get_image(img_path)\n",
    "        if img is not None and x is not None:\n",
    "            data.append({'x': np.array(x[0]), 'y': c})\n",
    "\n",
    "# Conta o número de classes\n",
    "num_classes = len(categories)\n",
    "\n",
    "print(f\"Total de classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embaralhar os Dados\n",
    "Essa etapa é importante para garantir que os dados estejam distribuídos aleatoriamente, o que ajuda a evitar vieses durante o treinamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de dados: 24998\n",
      "Primeiros 5 itens: [{'x': array([[[  53.060997 ,   52.221    ,   49.32     ],\n",
      "        [  54.060997 ,   53.221    ,   50.32     ],\n",
      "        [  54.060997 ,   53.221    ,   50.32     ],\n",
      "        ...,\n",
      "        [ -76.939    ,  -90.779    ,  -77.68     ],\n",
      "        [ -80.939    ,  -91.779    ,  -74.68     ],\n",
      "        [ -80.939    ,  -89.779    ,  -71.68     ]],\n",
      "\n",
      "       [[  51.060997 ,   50.221    ,   47.32     ],\n",
      "        [  54.060997 ,   53.221    ,   50.32     ],\n",
      "        [  57.060997 ,   56.221    ,   53.32     ],\n",
      "        ...,\n",
      "        [ -79.939    ,  -90.779    ,  -79.68     ],\n",
      "        [ -83.939    ,  -92.779    ,  -75.68     ],\n",
      "        [ -83.939    ,  -91.779    ,  -73.68     ]],\n",
      "\n",
      "       [[  57.060997 ,   56.221    ,   53.32     ],\n",
      "        [  57.060997 ,   56.221    ,   53.32     ],\n",
      "        [  56.060997 ,   55.221    ,   52.32     ],\n",
      "        ...,\n",
      "        [ -81.939    ,  -89.779    ,  -81.68     ],\n",
      "        [ -79.939    ,  -88.779    ,  -71.68     ],\n",
      "        [ -79.939    ,  -88.779    ,  -67.68     ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-100.939    , -108.779    , -114.68     ],\n",
      "        [-100.939    , -108.779    , -114.68     ],\n",
      "        [-100.939    , -108.779    , -114.68     ],\n",
      "        ...,\n",
      "        [ -35.939003 ,  -38.779    ,  -15.68     ],\n",
      "        [ -38.939003 ,  -48.779    ,  -17.68     ],\n",
      "        [ -17.939003 ,  -30.779    ,    2.3199997]],\n",
      "\n",
      "       [[-100.939    , -108.779    , -114.68     ],\n",
      "        [-100.939    , -108.779    , -114.68     ],\n",
      "        [-100.939    , -108.779    , -114.68     ],\n",
      "        ...,\n",
      "        [  -4.939003 ,   -8.778999 ,   18.32     ],\n",
      "        [ -42.939003 ,  -53.779    ,  -25.68     ],\n",
      "        [ -34.939003 ,  -46.779    ,  -19.68     ]],\n",
      "\n",
      "       [[-100.939    , -108.779    , -114.68     ],\n",
      "        [-100.939    , -108.779    , -114.68     ],\n",
      "        [-100.939    , -108.779    , -114.68     ],\n",
      "        ...,\n",
      "        [  15.060997 ,    8.221001 ,   38.32     ],\n",
      "        [ -29.939003 ,  -40.779    ,  -13.68     ],\n",
      "        [ -29.939003 ,  -40.779    ,  -17.68     ]]], dtype=float32), 'y': 0}, {'x': array([[[ -66.939    ,  -86.779    ,  -90.68     ],\n",
      "        [ -70.939    ,  -89.779    ,  -95.68     ],\n",
      "        [ -80.939    ,  -99.779    , -105.68     ],\n",
      "        ...,\n",
      "        [ -48.939003 ,  -50.779    ,  -73.68     ],\n",
      "        [ -70.939    ,  -73.779    ,  -92.68     ],\n",
      "        [ -83.939    ,  -88.779    , -102.68     ]],\n",
      "\n",
      "       [[ -85.939    ,  -94.779    , -107.68     ],\n",
      "        [ -85.939    ,  -94.779    , -107.68     ],\n",
      "        [ -88.939    ,  -97.779    , -109.68     ],\n",
      "        ...,\n",
      "        [ -41.939003 ,  -44.779    ,  -67.68     ],\n",
      "        [ -78.939    ,  -83.779    , -101.68     ],\n",
      "        [ -90.939    ,  -96.779    , -110.68     ]],\n",
      "\n",
      "       [[ -88.939    ,  -92.779    , -109.68     ],\n",
      "        [ -90.939    ,  -94.779    , -111.68     ],\n",
      "        [ -92.939    ,  -97.779    , -111.68     ],\n",
      "        ...,\n",
      "        [ -47.939003 ,  -51.779    ,  -71.68     ],\n",
      "        [ -76.939    ,  -81.779    ,  -98.68     ],\n",
      "        [ -88.939    ,  -94.779    , -108.68     ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -16.939003 ,   17.221    ,  -27.68     ],\n",
      "        [  -8.939003 ,   21.221    ,  -22.68     ],\n",
      "        [  24.060997 ,   44.221    ,    2.3199997],\n",
      "        ...,\n",
      "        [ -40.939003 ,    4.2210007,  -50.68     ],\n",
      "        [ -21.939003 ,   18.221    ,  -28.68     ],\n",
      "        [ -19.939003 ,   14.221001 ,  -25.68     ]],\n",
      "\n",
      "       [[ -23.939003 ,   13.221001 ,  -25.68     ],\n",
      "        [  10.060997 ,   24.221    ,   -8.68     ],\n",
      "        [  30.060997 ,   48.221    ,   10.32     ],\n",
      "        ...,\n",
      "        [ -51.939003 ,   -7.7789993,  -45.68     ],\n",
      "        [ -41.939003 ,   -0.7789993,  -42.68     ],\n",
      "        [ -14.939003 ,   24.221    ,  -22.68     ]],\n",
      "\n",
      "       [[  -9.939003 ,   29.221    ,   -7.6800003],\n",
      "        [  11.060997 ,   22.221    ,   -8.68     ],\n",
      "        [  23.060997 ,   40.221    ,    4.3199997],\n",
      "        ...,\n",
      "        [ -18.939003 ,   24.221    ,   -5.6800003],\n",
      "        [ -47.939003 ,   -5.7789993,  -45.68     ],\n",
      "        [  12.060997 ,   51.221    ,    4.3199997]]], dtype=float32), 'y': 1}, {'x': array([[[-32.939003, -41.779   , -60.68    ],\n",
      "        [-38.939003, -49.779   , -62.68    ],\n",
      "        [-16.939003, -28.779   , -45.68    ],\n",
      "        ...,\n",
      "        [-12.939003, -25.779   , -50.68    ],\n",
      "        [-13.939003, -26.779   , -51.68    ],\n",
      "        [-13.939003, -24.779   , -50.68    ]],\n",
      "\n",
      "       [[-34.939003, -43.779   , -62.68    ],\n",
      "        [-36.939003, -47.779   , -60.68    ],\n",
      "        [-15.939003, -27.779   , -44.68    ],\n",
      "        ...,\n",
      "        [-12.939003, -25.779   , -50.68    ],\n",
      "        [-13.939003, -26.779   , -51.68    ],\n",
      "        [-13.939003, -24.779   , -50.68    ]],\n",
      "\n",
      "       [[-36.939003, -42.779   , -64.68    ],\n",
      "        [-27.939003, -38.779   , -51.68    ],\n",
      "        [-15.939003, -26.779   , -45.68    ],\n",
      "        ...,\n",
      "        [-12.939003, -25.779   , -50.68    ],\n",
      "        [-12.939003, -25.779   , -50.68    ],\n",
      "        [-14.939003, -25.779   , -51.68    ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-70.939   , -78.779   , -82.68    ],\n",
      "        [-72.939   , -84.779   , -87.68    ],\n",
      "        [-71.939   , -82.779   , -88.68    ],\n",
      "        ...,\n",
      "        [-73.939   , -83.779   , -92.68    ],\n",
      "        [-72.939   , -82.779   , -91.68    ],\n",
      "        [-73.939   , -81.779   , -90.68    ]],\n",
      "\n",
      "       [[-72.939   , -80.779   , -84.68    ],\n",
      "        [-72.939   , -84.779   , -87.68    ],\n",
      "        [-72.939   , -83.779   , -89.68    ],\n",
      "        ...,\n",
      "        [-72.939   , -82.779   , -91.68    ],\n",
      "        [-71.939   , -81.779   , -90.68    ],\n",
      "        [-73.939   , -80.779   , -92.68    ]],\n",
      "\n",
      "       [[-70.939   , -78.779   , -82.68    ],\n",
      "        [-72.939   , -84.779   , -87.68    ],\n",
      "        [-71.939   , -82.779   , -88.68    ],\n",
      "        ...,\n",
      "        [-72.939   , -82.779   , -91.68    ],\n",
      "        [-71.939   , -81.779   , -90.68    ],\n",
      "        [-73.939   , -81.779   , -90.68    ]]], dtype=float32), 'y': 1}, {'x': array([[[ 79.061    , 116.221    ,  99.32     ],\n",
      "        [ 14.060997 ,  48.221    ,  32.32     ],\n",
      "        [ 15.060997 ,  54.221    ,  37.32     ],\n",
      "        ...,\n",
      "        [ -4.939003 ,  76.221    ,  45.32     ],\n",
      "        [-10.939003 ,  73.221    ,  39.32     ],\n",
      "        [-14.939003 ,  55.221    ,  26.32     ]],\n",
      "\n",
      "       [[ 52.060997 ,  89.221    ,  72.32     ],\n",
      "        [ 32.060997 ,  64.221    ,  48.32     ],\n",
      "        [ 32.060997 ,  69.221    ,  52.32     ],\n",
      "        ...,\n",
      "        [-18.939003 ,  55.221    ,  28.32     ],\n",
      "        [ -0.939003 ,  76.221    ,  46.32     ],\n",
      "        [ 35.060997 ,  87.221    ,  65.32     ]],\n",
      "\n",
      "       [[ 43.060997 ,  80.221    ,  63.32     ],\n",
      "        [ 50.060997 ,  82.221    ,  66.32     ],\n",
      "        [ 46.060997 ,  83.221    ,  66.32     ],\n",
      "        ...,\n",
      "        [ -1.939003 ,  62.221    ,  41.32     ],\n",
      "        [ 29.060997 ,  94.221    ,  70.32     ],\n",
      "        [ 42.060997 ,  80.221    ,  65.32     ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-31.939003 ,  21.221    ,   3.3199997],\n",
      "        [-73.939    ,  -6.7789993, -30.68     ],\n",
      "        [ 14.060997 ,  89.221    ,  58.32     ],\n",
      "        ...,\n",
      "        [ 34.060997 , 107.221    ,  94.32     ],\n",
      "        [-34.939003 ,  29.221    ,  19.32     ],\n",
      "        [-18.939003 ,  30.221    ,  34.32     ]],\n",
      "\n",
      "       [[-47.939003 ,   2.2210007,  -6.6800003],\n",
      "        [ 56.060997 ,  96.221    ,  79.32     ],\n",
      "        [ 13.060997 ,  73.221    ,  44.32     ],\n",
      "        ...,\n",
      "        [  4.060997 ,  71.221    ,  57.32     ],\n",
      "        [-31.939003 ,  32.221    ,  17.32     ],\n",
      "        [-21.939003 ,  37.221    ,  30.32     ]],\n",
      "\n",
      "       [[-43.939003 ,   3.2210007,  -3.6800003],\n",
      "        [ 42.060997 ,  76.221    ,  60.32     ],\n",
      "        [-29.939003 ,  27.221    ,  -2.6800003],\n",
      "        ...,\n",
      "        [-24.939003 ,  39.221    ,  25.32     ],\n",
      "        [-31.939003 ,  31.221    ,  13.32     ],\n",
      "        [ -0.939003 ,  60.221    ,  49.32     ]]], dtype=float32), 'y': 1}, {'x': array([[[ 25.060997 ,  22.221    ,  25.32     ],\n",
      "        [ 23.060997 ,  19.221    ,  25.32     ],\n",
      "        [ 35.060997 ,  34.221    ,  39.32     ],\n",
      "        ...,\n",
      "        [-35.939003 , -19.779    ,   4.3199997],\n",
      "        [-36.939003 , -18.779    ,   5.3199997],\n",
      "        [-37.939003 , -19.779    ,   4.3199997]],\n",
      "\n",
      "       [[ 33.060997 ,  30.221    ,  33.32     ],\n",
      "        [ 30.060997 ,  26.221    ,  32.32     ],\n",
      "        [ 32.060997 ,  31.221    ,  36.32     ],\n",
      "        ...,\n",
      "        [-34.939003 , -18.779    ,   5.3199997],\n",
      "        [-36.939003 , -18.779    ,   5.3199997],\n",
      "        [-36.939003 , -18.779    ,   5.3199997]],\n",
      "\n",
      "       [[ 34.060997 ,  30.221    ,  36.32     ],\n",
      "        [ 35.060997 ,  31.221    ,  37.32     ],\n",
      "        [ 30.060997 ,  29.221    ,  34.32     ],\n",
      "        ...,\n",
      "        [-34.939003 , -19.779    ,   7.3199997],\n",
      "        [-36.939003 , -18.779    ,   7.3199997],\n",
      "        [-36.939003 , -18.779    ,   7.3199997]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 56.060997 ,  55.221    ,  52.32     ],\n",
      "        [ 56.060997 ,  55.221    ,  52.32     ],\n",
      "        [ 54.060997 ,  53.221    ,  52.32     ],\n",
      "        ...,\n",
      "        [-45.939003 , -21.779    ,   9.32     ],\n",
      "        [-53.939003 , -24.779    ,  11.32     ],\n",
      "        [-57.939003 , -28.779    ,  11.32     ]],\n",
      "\n",
      "       [[ 55.060997 ,  54.221    ,  53.32     ],\n",
      "        [ 55.060997 ,  54.221    ,  53.32     ],\n",
      "        [ 53.060997 ,  52.221    ,  51.32     ],\n",
      "        ...,\n",
      "        [-36.939003 , -10.778999 ,  20.32     ],\n",
      "        [-56.939003 , -27.779    ,   8.32     ],\n",
      "        [-55.939003 , -25.779    ,  16.32     ]],\n",
      "\n",
      "       [[ 49.060997 ,  48.221    ,  47.32     ],\n",
      "        [ 50.060997 ,  49.221    ,  48.32     ],\n",
      "        [ 50.060997 ,  49.221    ,  48.32     ],\n",
      "        ...,\n",
      "        [-24.939003 ,   3.2210007,  35.32     ],\n",
      "        [-59.939003 , -30.779    ,   7.3199997],\n",
      "        [-60.939003 , -30.779    ,  11.32     ]]], dtype=float32), 'y': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Embaralha a ordem dos dados\n",
    "random.shuffle(data)\n",
    "\n",
    "\n",
    "# Verifica se os dados foram embaralhados corretamente\n",
    "print(f\"Total de dados: {len(data)}\")\n",
    "print(f\"Primeiros 5 itens: {data[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir os Dados em Treinamento, Validação e Teste\n",
    "\n",
    "Nesta etapa, vamos dividir os dados em três conjuntos: treinamento (70%), validação (15%) e teste (15%). Isso nos permitirá **treinar o modelo com o conjunto de treinamento**, **ajustar os hiperparâmetros com o conjunto de validação** e **avaliar o desempenho final com o conjunto de teste.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de dados de treinamento: 17498\n",
      "Total de dados de validação: 3750\n",
      "Total de dados de teste: 3750\n"
     ]
    }
   ],
   "source": [
    "# Define as proporções para divisão dos dados\n",
    "train_split, val_split = 0.7, 0.15\n",
    "\n",
    "# Calcula os índices para divisão dos dados\n",
    "idx_val = int(train_split * len(data))\n",
    "idx_test = int((train_split + val_split) * len(data))\n",
    "\n",
    "# Divide os dados em treinamento, validação e teste\n",
    "train = data[:idx_val]\n",
    "val = data[idx_val:idx_test]\n",
    "test = data[idx_test:]\n",
    "\n",
    "# Imprime o tamanho de cada conjunto para verificar a divisão\n",
    "print(f\"Total de dados de treinamento: {len(train)}\")\n",
    "print(f\"Total de dados de validação: {len(val)}\")\n",
    "print(f\"Total de dados de teste: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separar os Dados dos Rótulos\n",
    "\n",
    "Agora, vamos separar os dados (imagens) dos rótulos para cada um dos conjuntos: treinamento, validação e teste. Isso facilita o uso dos dados nos processos de treinamento e avaliação do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "# Separa os dados (imagens) dos rótulos para cada conjunto\n",
    "x_train = np.array([t[\"x\"] for t in train])\n",
    "y_train = [t[\"y\"] for t in train]\n",
    "\n",
    "x_val = np.array([t[\"x\"] for t in val])\n",
    "y_val = [t[\"y\"] for t in val]\n",
    "\n",
    "x_test = np.array([t[\"x\"] for t in test])\n",
    "y_test = [t[\"y\"] for t in test]\n",
    "\n",
    "# Imprime os rótulos do conjunto de teste para verificação\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
