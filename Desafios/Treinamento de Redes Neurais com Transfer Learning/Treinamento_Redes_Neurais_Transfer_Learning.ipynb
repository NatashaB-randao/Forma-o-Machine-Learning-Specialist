{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "**Transfer Learning (ou Aprendizagem por Transferência)** é uma técnica em Machine Learning e Deep Learning onde um modelo treinado em uma tarefa é reutilizado como o ponto de partida para um modelo em uma segunda tarefa relacionada. Em vez de treinar um modelo do zero, o que pode ser muito demorado e requerer grandes quantidades de dados, Transfer Learning aproveita o conhecimento já adquirido em um modelo pré-treinado para acelerar e melhorar o desempenho em uma nova tarefa.\n",
    "\n",
    "### Funcionamento do Transfer Learning\n",
    "\n",
    "1. **Modelo Pré-treinado**: Um modelo é treinado em um grande conjunto de dados e em uma tarefa específica (por exemplo, a classificação de imagens no ImageNet).\n",
    "2. **Transferência do Conhecimento**: As camadas iniciais desse modelo capturam características genéricas das imagens (como bordas, texturas, formas), enquanto as camadas finais são mais específicas para a tarefa original. No Transfer Learning, essas camadas iniciais são reutilizadas.\n",
    "3. **Adaptação**: O modelo é então ajustado para a nova tarefa, que pode envolver:\n",
    "   - **Congelar** algumas das camadas iniciais e treinar apenas as últimas camadas com o novo conjunto de dados.\n",
    "   - **Treinamento Fino (Fine-tuning)**, onde todo o modelo é treinado novamente com uma taxa de aprendizado mais baixa.\n",
    "\n",
    "### Aplicação Prática\n",
    "\n",
    "Neste projeto, estamos utilizando um modelo pré-treinado em um dataset bem conhecido (como o ImageNet) e adaptando esse modelo para classificar imagens de gatos e cachorros. A abordagem geral inclui os seguintes passos:\n",
    "\n",
    "1. **Carregar o modelo pré-treinado**: Utilizando bibliotecas como Keras, TensorFlow ou PyTorch para carregar um modelo que já foi treinado em um grande conjunto de dados.\n",
    "2. **Modificar a arquitetura**: Adaptar a última camada do modelo para ter o mesmo número de classes que o nosso problema (neste caso, duas classes: gatos e cachorros).\n",
    "3. **Congelar camadas**: Congelar algumas das primeiras camadas do modelo para preservar as características genéricas aprendidas.\n",
    "4. **Treinar o modelo**: Usar nosso conjunto de dados específico (gatos e cachorros) para ajustar as camadas finais do modelo e refinar o desempenho.\n",
    "\n",
    "### Exemplo no COLAB\n",
    "\n",
    "O exemplo no link [Transfer Learning com o Dataset MNIST](https://colab.research.google.com/github/kylemath/ml4a-guides/blob/master/notebooks/transfer-learning.ipynb) demonstra como aplicar Transfer Learning usando o dataset MNIST. Para este projeto, seguimos uma abordagem similar, mas adaptando para o dataset de gatos e cachorros, conforme descrito no link [Cats vs Dogs Dataset](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs).\n",
    "\n",
    "### Benefícios do Transfer Learning\n",
    "\n",
    "- **Redução do Tempo de Treinamento**: O modelo já tem um bom entendimento das características básicas das imagens, então o tempo necessário para treinar é reduzido.\n",
    "- **Menos Dados Necessários**: Como o modelo já foi treinado em uma grande quantidade de dados, a quantidade de dados necessária para a nova tarefa é menor.\n",
    "- **Melhor Desempenho**: Utilizando um modelo pré-treinado que já foi ajustado para capturar características relevantes, o desempenho na nova tarefa pode ser melhor do que treinar um modelo do zero.\n",
    "\n",
    "### Exemplos Comuns\n",
    "\n",
    "Transfer Learning é amplamente utilizado em várias áreas, como:\n",
    "- **Visão Computacional**: Classificação de imagens, detecção de objetos, segmentação de imagens.\n",
    "- **Processamento de Linguagem Natural (NLP)**: Tradução de texto, classificação de texto, resposta a perguntas.\n",
    "- **Reconhecimento de Voz**: Identificação de locutores, transcrição de fala.\n",
    "\n",
    "### Conclusão\n",
    "\n",
    "Transfer Learning é uma poderosa técnica em Deep Learning que permite reutilizar e adaptar modelos pré-treinados para novas tarefas, economizando tempo e recursos e melhorando o desempenho em tarefas relacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Importa o módulo os para interagir com o sistema operacional, como manipulação de diretórios e variáveis de ambiente\n",
    "\n",
    "# if using Theano with GPU\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # Define o backend do Keras para TensorFlow caso esteja usando Theano com GPU (comentado, pois estamos usando TensorFlow por padrão)\n",
    "\n",
    "import random  # Importa o módulo random para gerar números aleatórios\n",
    "import numpy as np  # Importa o numpy com o alias np, uma biblioteca fundamental para computação numérica em Python\n",
    "import keras  # Importa o Keras, uma biblioteca popular de deep learning que fornece uma API simples para construção e treinamento de modelos de redes neurais\n",
    "\n",
    "import matplotlib.pyplot as plt  # Importa matplotlib.pyplot com o alias plt, uma biblioteca para plotagem de gráficos em Python\n",
    "from matplotlib.pyplot import imshow  # Importa a função imshow do matplotlib.pyplot para exibir imagens\n",
    "\n",
    "from keras.preprocessing import image  # Importa submódulos de pré-processamento de imagens do Keras, úteis para carregar e pré-processar imagens\n",
    "from keras.applications.imagenet_utils import preprocess_input  # Importa preprocess_input de keras.applications.imagenet_utils, uma função para pré-processar imagens de acordo com o padrão do ImageNet\n",
    "from keras.models import Sequential  # Importa a classe Sequential do Keras para criar modelos sequenciais de redes neurais\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation  # Importa camadas específicas do Keras usadas na construção de redes neurais\n",
    "from keras.layers import Conv2D, MaxPooling2D  # Importa camadas convolucionais (Conv2D) e de max pooling (MaxPooling2D), fundamentais para processar dados de imagem em redes convolucionais\n",
    "from keras.models import Model  # Importa a classe Model do Keras para criar modelos mais complexos e customizados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo um Dataset\n",
    "\n",
    "O primeiro passo é carregar nossos dados. Para este exemplo, utilizaremos o dataset de Gatos e Cachorros, que contém imagens rotuladas de duas categorias: gatos e cachorros. O dataset já está organizado com imagens divididas em pastas para cada classe.\n",
    "\n",
    "Para obter este dataset, você pode seguir estas etapas:\n",
    "\n",
    "1. **Baixar o dataset**: Utilize o comando `wget` para baixar o dataset, ou você pode usar o link direto para o download. Aqui estão os comandos:\n",
    "\n",
    "    ```bash\n",
    "    wget https://www.microsoft.com/en-us/download/details.aspx?id=54765\n",
    "    ```\n",
    "\n",
    "    Se necessário, descompacte o arquivo:\n",
    "\n",
    "    ```bash\n",
    "    tar -xvzf nome_do_arquivo.tar.gz\n",
    "    ```\n",
    "\n",
    "2. **Organizar o dataset**: Certifique-se de que seu dataset esteja organizado da seguinte forma:\n",
    "    - O diretório principal deve conter subpastas para cada classe (neste caso, uma subpasta para \"gatos\" e outra para \"cachorros\").\n",
    "    - Cada subpasta deve conter as imagens correspondentes à sua classe.\n",
    "\n",
    "3. **Carregar o dataset**: Substitua `root` pelo caminho para o seu diretório de dataset. O código abaixo carrega o dataset personalizado, redimensiona as imagens para 224x224 pixels (necessário para a entrada da VGG16), e prepara as imagens para serem usadas no modelo.\n",
    "\n",
    "    ```python\n",
    "    root = 'caminho/para/seu/dataset'\n",
    "    \n",
    "    # Lista de categorias (pastas) que você deseja incluir no treinamento\n",
    "    categorias = [x[0] for x in os.walk(root) if x[0]][1:]\n",
    "    \n",
    "    # Imprime as categorias disponíveis no dataset\n",
    "    print(categorias)\n",
    "    ```\n",
    "\n",
    "Certifique-se de que a estrutura do diretório esteja correta para que o código funcione corretamente. Se você tiver um estrutura diferente, adapte o código conforme necessário para carregar os dados corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "root = 'Desafios/Treinamento de Redes Neurais com Transfer Learning/kagglecatsanddogs_5340'\n",
    "\n",
    "# Lista de categorias (pastas) que você deseja incluir no treinamento\n",
    "categorias = [x[0] for x in os.walk(root) if x[0]][1:]\n",
    "\n",
    "# Imprime as categorias disponíveis no dataset\n",
    "print(categorias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Pré-processamento de Imagens\n",
    "\n",
    "Esta função é útil para pré-processar os dados, transformando uma imagem em um vetor de entrada adequado para o modelo.\n",
    "\n",
    "A função get_image carrega uma imagem, redimensiona-a para 224x224 pixels (o tamanho de entrada esperado pela VGG16), e a prepara para ser alimentada na rede neural. A função retorna a imagem original e o vetor de entrada pré-processado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar para carregar a imagem e retornar a imagem e o vetor de entrada\n",
    "\n",
    "def get_image(path):\n",
    "    # Carrega a imagem com o tamanho de entrada esperado (224x224 pixels)\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "\n",
    "    # Converte a imagem em um array numpy\n",
    "    x = image.img_to_array(img)\n",
    "\n",
    "    # Adiciona uma dimensão extra ao array para criar um batch do tamanho 1\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    #Pré-processa a imagem para o modelo (no caso da VGG16)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    return img, x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
